{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os import path\n",
    "\n",
    "# Directory where data is stored\n",
    "DATA_DIR = '../resources/code-soccer-files-main/data'\n",
    "\n",
    "# Load the CSV data\n",
    "df = pd.read_csv(path.join(DATA_DIR, 'player_match.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing\n",
    " \n",
    "# Fill missing values with 0\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# Group by player_id and aggregate\n",
    "columns_to_convert = ['shot', 'goal', 'goal_allowed', 'assist', 'pass', 'pass_accurate', 'tackle', \n",
    "                     'accel', 'counter', 'opportunity', 'keypass', 'own_goal', 'interception', \n",
    "                     'smart', 'clearance', 'cross', 'air_duel', 'air_duel_won', 'gk_leave_line', \n",
    "                     'gk_save_attempt', 'throw', 'corner']\n",
    "\n",
    "agg_funcs = {col: 'sum' for col in columns_to_convert}\n",
    "agg_funcs['min'] = 'sum'  # Make sure to sum up the minutes as well\n",
    "grouped = df.groupby('player_id').agg(agg_funcs).reset_index()\n",
    "\n",
    "# a small value to avoid division by zero\n",
    "epsilon = 1e-10 \n",
    "\n",
    "# Calculate per 90 metrics for relevant columns\n",
    "for col in columns_to_convert:\n",
    "    grouped[col+'_per_90'] = (grouped[col] / (grouped['min'] + epsilon)) * 90\n",
    "\n",
    "# Save the grouped DataFrame to a new CSV file\n",
    "grouped.to_csv('player_per_90.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create a copy of the grouped DataFrame for normalization\n",
    "normalized_per_90 = grouped.copy()\n",
    "\n",
    "# Normalize the per 90 metrics\n",
    "scaler = StandardScaler()\n",
    "columns_to_normalize = [col+'_per_90' for col in columns_to_convert]\n",
    "normalized_per_90[columns_to_normalize] = scaler.fit_transform(normalized_per_90[columns_to_normalize])\n",
    "\n",
    "# Save the grouped DataFrame to a CSV file\n",
    "grouped.to_csv('player_per_90.csv', index=False)\n",
    "\n",
    "# Save the normalized DataFrame to a new CSV file\n",
    "normalized_per_90.to_csv('player_per_90_normalized.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of the 5 most similar players to player at index 0: [0 4 3 7 5]\n",
      "Distances: [    0.     8330.235 21798.494 28163.    33589.23 ]\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# Assuming df_normalized from previous steps is your DataFrame with player vectors\n",
    "vectors = normalized_per_90.values.astype('float32')\n",
    "\n",
    "# Build the index\n",
    "index = faiss.IndexFlatL2(vectors.shape[1])\n",
    "index.add(vectors)\n",
    "\n",
    "# Search for the 5 most similar players to the player at index 0\n",
    "D, I = index.search(vectors[0:1], 5)\n",
    "\n",
    "print(f\"Indices of the 5 most similar players to player at index 0: {I[0]}\")\n",
    "print(f\"Distances: {D[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load the CSV file and extract only the player_id and player_name columns\n",
    "names_df = pd.read_csv(path.join(DATA_DIR, 'players.csv'))[['player_id', 'player_name']]\n",
    "\n",
    "# 1. Create transformations for player_id to player_name and vice versa using names_df\n",
    "id_to_name = pd.Series(names_df.player_name.values, index=names_df.player_id).to_dict()\n",
    "name_to_id = {v: k for k, v in id_to_name.items()}\n",
    "\n",
    "# Adjust the id_to_index and index_to_id mappings to use the player IDs from normalized_df\n",
    "id_to_index = {player_id: idx for idx, player_id in enumerate(normalized_per_90['player_id'])}\n",
    "index_to_id = {idx: player_id for player_id, idx in id_to_index.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_players(player_name, columns=None, k=5):\n",
    "    # If no columns are specified, use all columns in normalized_df (excluding 'player_id')\n",
    "    if columns is None:\n",
    "        columns = [col for col in normalized_per_90.columns if col != 'player_id']\n",
    "    \n",
    "    # Extract vectors based on the specified columns\n",
    "    specific_vectors = normalized_per_90[columns].values.astype('float32')\n",
    "    \n",
    "    # Build the FAISS index for the specified vectors\n",
    "    specific_index = faiss.IndexFlatL2(specific_vectors.shape[1])\n",
    "    specific_index.add(specific_vectors)\n",
    "    \n",
    "    # Find the player_id corresponding to the player_name using name_to_id\n",
    "    if player_name not in name_to_id:\n",
    "        return f\"Player {player_name} not found in the dataset.\"\n",
    "    \n",
    "    player_id = name_to_id[player_name]\n",
    "    \n",
    "    # Get the vector for the given player_id based on the specified columns\n",
    "    player_vector = specific_vectors[id_to_index[player_id]].reshape(1, -1)\n",
    "    \n",
    "    # Search for the k most similar players in FAISS using the specific index\n",
    "    D, I = specific_index.search(player_vector, k+1)  # k+1 because the player will be most similar to themselves\n",
    "    \n",
    "    # Convert indices to player_ids and then use id_to_name to get player names, excluding the input player\n",
    "    similar_players_ids = [index_to_id[idx] for idx in I[0] if idx != id_to_index[player_id]]\n",
    "    similar_players_names = [id_to_name[player_id] for player_id in similar_players_ids]\n",
    "    \n",
    "    return similar_players_names[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Players most similar to L. Messi:\n",
      "['X. Shaqiri', 'Salem Al Dawsari', 'A. Griezmann', 'Yasir Al Shahrani', 'S. Arias']\n"
     ]
    }
   ],
   "source": [
    "# Test the function\n",
    "player_name = \"L. Messi\"\n",
    "comparison_cols = ['shot', 'goal', 'goal_allowed', 'assist', 'pass', 'pass_accurate', 'tackle', 'accel', 'counter', 'opportunity', 'keypass']    #['shot', 'goal', 'goal_allowed', 'assist', 'pass', 'pass_accurate', 'tackle', 'accel', 'counter', 'opportunity', 'keypass', 'own_goal', 'interception', 'smart', 'clearance', 'cross', 'air_duel', 'air_duel_won', 'gk_leave_line', 'gk_save_attempt', 'throw', 'corner']\n",
    "print(f\"Players most similar to {player_name}:\")\n",
    "print(find_similar_players(player_name, comparison_cols))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
